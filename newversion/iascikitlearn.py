"""
=============================================================================
ðŸšŒ EXERCICE : Apprendre le Random Forest avec un cas de transport bus
=============================================================================

Objectif : EntraÃ®ner une IA Ã  prÃ©dire quel bus doit effectuer un voyage,
           en se basant sur des donnÃ©es historiques simulÃ©es.

Niveau : DÃ©butant en Machine Learning
PrÃ©requis : Bases Python (variables, fonctions, boucles)

ðŸŽ¯ Ce que tu vas apprendre :
   1. PrÃ©parer des donnÃ©es pour le ML
   2. EntraÃ®ner un modÃ¨le Random Forest
   3. Ã‰valuer ses performances
   4. Faire des prÃ©dictions sur de nouveaux voyages
   5. Tracer une courbe d'apprentissage (learning curve)

Instructions : Lis le code, complÃ¨te les parties marquÃ©es "Ã€ TOI DE JOUER"
               puis exÃ©cute le script pour voir les rÃ©sultats.
=============================================================================
"""

# =============================================
# PARTIE 1 : LES IMPORTS
# =============================================
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, learning_curve
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt

print("âœ… BibliothÃ¨ques importÃ©es avec succÃ¨s !\n")


# =============================================
# PARTIE 2 : CRÃ‰ER DES DONNÃ‰ES SIMULÃ‰ES
# =============================================
# On simule des plannings historiques de 5 bus sur plusieurs jours
# Dans ton vrai projet, tu remplaceras Ã§a par tes fichiers Excel

np.random.seed(42)


def generer_donnees(n_jours=60):
    """
    GÃ©nÃ¨re des donnÃ©es de voyages simulÃ©es.
    On utilise 60 jours pour avoir assez de donnÃ©es
    pour la courbe d'apprentissage.
    """
    voyages = []
    lignes = ["L1", "L2", "L3"]
    terminus = ["A", "B", "C", "D"]

    for jour in range(n_jours):
        for heure_depart in range(360, 1320, 15):  # de 6h Ã  22h toutes les 15 min
            if np.random.random() > 0.3:
                continue

            ligne = np.random.choice(lignes)
            origine = np.random.choice(terminus)
            destination = np.random.choice([t for t in terminus if t != origine])
            duree = np.random.randint(20, 60)

            # RÃ¨gles cachÃ©es que le modÃ¨le devra apprendre :
            # - Bus_1/Bus_2 â†’ ligne L1 (matin/aprÃ¨s-midi)
            # - Bus_3 â†’ ligne L2
            # - Bus_4/Bus_5 â†’ ligne L3 (matin/aprÃ¨s-midi)
            if ligne == "L1":
                if heure_depart < 720:
                    bus = np.random.choice(["Bus_1", "Bus_1", "Bus_1", "Bus_2"])
                else:
                    bus = np.random.choice(["Bus_2", "Bus_2", "Bus_2", "Bus_1"])
            elif ligne == "L2":
                bus = np.random.choice(["Bus_3", "Bus_3", "Bus_3", "Bus_4"])
            else:
                if heure_depart < 720:
                    bus = np.random.choice(["Bus_4", "Bus_4", "Bus_4", "Bus_5"])
                else:
                    bus = np.random.choice(["Bus_5", "Bus_5", "Bus_5", "Bus_4"])

            voyages.append({
                "jour": jour,
                "heure_depart": heure_depart,
                "heure_arrivee": heure_depart + duree,
                "ligne": ligne,
                "origine": origine,
                "destination": destination,
                "duree": duree,
                "bus": bus,
            })

    return pd.DataFrame(voyages)


df = generer_donnees(n_jours=60)
print(f"ðŸ“Š DonnÃ©es gÃ©nÃ©rÃ©es : {len(df)} voyages sur 60 jours")
print(f"   Colonnes : {list(df.columns)}")
print(f"\nðŸ” AperÃ§u des 5 premiÃ¨res lignes :")
print(df.head().to_string())
print()


# =============================================
# PARTIE 3 : PRÃ‰PARER LES DONNÃ‰ES (FEATURES)
# =============================================
print("=" * 50)
print("ðŸ“ PARTIE 3 : PrÃ©paration des features")
print("=" * 50)

# --- Ã€ TOI DE JOUER (Exercice 1) ---
# CrÃ©e la variable 'features' en utilisant pd.get_dummies()
# sur les colonnes : ligne, origine, destination
# Puis ajoute les colonnes numÃ©riques : heure_depart, duree
#
# ðŸ’¡ DÃ‰COMMENTE ET COMPLÃˆTE :
# features = pd.get_dummies(df[[???]])
# features["heure_depart"] = ???
# features["duree"] = ???

# ---- SOLUTION ----
features = pd.get_dummies(df[["ligne", "origine", "destination"]])
features["heure_depart"] = df["heure_depart"]
features["duree"] = df["duree"]
# ---- FIN SOLUTION ----

cible = df["bus"]

print(f"\nâœ… Features crÃ©Ã©es : {features.shape[1]} colonnes")
print(f"   Colonnes : {list(features.columns)}")
print(f"   Cible : {cible.nunique()} bus diffÃ©rents ({list(cible.unique())})")
print()


# =============================================
# PARTIE 4 : SÃ‰PARER DONNÃ‰ES TRAIN / TEST
# =============================================
print("=" * 50)
print("ðŸ”€ PARTIE 4 : SÃ©paration train / test")
print("=" * 50)

# --- Ã€ TOI DE JOUER (Exercice 2) ---
# ðŸ’¡ DÃ‰COMMENTE ET COMPLÃˆTE :
# X_train, X_test, y_train, y_test = train_test_split(???, ???, test_size=0.2, random_state=42)

# ---- SOLUTION ----
X_train, X_test, y_train, y_test = train_test_split(
    features, cible, test_size=0.2, random_state=42
)
# ---- FIN SOLUTION ----

print(f"   DonnÃ©es d'entraÃ®nement : {len(X_train)} voyages")
print(f"   DonnÃ©es de test :        {len(X_test)} voyages")
print()


# =============================================
# PARTIE 5 : ENTRAÃŽNER LE MODÃˆLE ðŸš€
# =============================================
print("=" * 50)
print("ðŸ§  PARTIE 5 : EntraÃ®nement du Random Forest")
print("=" * 50)

# --- Ã€ TOI DE JOUER (Exercice 3) ---
# ðŸ’¡ DÃ‰COMMENTE ET COMPLÃˆTE :
# modele = RandomForestClassifier(n_estimators=???, random_state=???)
# modele.???(X_train, y_train)

# ---- SOLUTION ----
modele = RandomForestClassifier(n_estimators=100, random_state=42)
modele.fit(X_train, y_train)
# ---- FIN SOLUTION ----

print("âœ… ModÃ¨le entraÃ®nÃ© !")
print(f"   Nombre d'arbres : {modele.n_estimators}")
print()


# =============================================
# PARTIE 6 : Ã‰VALUER LE MODÃˆLE
# =============================================
print("=" * 50)
print("ðŸ“ˆ PARTIE 6 : Ã‰valuation")
print("=" * 50)

predictions = modele.predict(X_test)
precision = accuracy_score(y_test, predictions)
print(f"\nðŸŽ¯ PrÃ©cision du modÃ¨le : {precision:.1%}")
print(f"   (Le modÃ¨le attribue le bon bus {precision:.1%} du temps)\n")

print("ðŸ“‹ DÃ©tail par bus :")
print(classification_report(y_test, predictions))


# =============================================
# PARTIE 7 : COMPRENDRE LE MODÃˆLE
# =============================================
print("=" * 50)
print("ðŸ” PARTIE 7 : Quelles features sont les plus importantes ?")
print("=" * 50)

importances = pd.Series(
    modele.feature_importances_, index=features.columns
).sort_values(ascending=False)

print("\nImportance des features :")
for feature, importance in importances.items():
    barre = "â–ˆ" * int(importance * 50)
    print(f"   {feature:20s} : {importance:.3f} {barre}")


# =============================================
# PARTIE 8 : PRÃ‰DIRE PLUSIEURS VOYAGES ðŸ”®
# =============================================
print("\n" + "=" * 50)
print("ðŸ”® PARTIE 8 : PrÃ©dire plusieurs nouveaux voyages")
print("=" * 50)

# --- Ã€ TOI DE JOUER (Exercice 4) ---
# Modifie cette liste pour tester tes propres scÃ©narios !
# Tu peux ajouter autant de voyages que tu veux.

nouveaux_voyages = [
    {"ligne": "L1", "origine": "A", "destination": "B", "heure_depart": 480, "duree": 35},   # L1, 8h00, matin
    {"ligne": "L1", "origine": "B", "destination": "A", "heure_depart": 840, "duree": 40},   # L1, 14h00, aprÃ¨s-midi
    {"ligne": "L2", "origine": "C", "destination": "D", "heure_depart": 600, "duree": 45},   # L2, 10h00
    {"ligne": "L3", "origine": "D", "destination": "A", "heure_depart": 420, "duree": 30},   # L3, 7h00, matin
    {"ligne": "L3", "origine": "A", "destination": "C", "heure_depart": 960, "duree": 50},   # L3, 16h00, aprÃ¨s-midi
    {"ligne": "L2", "origine": "D", "destination": "B", "heure_depart": 1080, "duree": 25},  # L2, 18h00, soir
]

# PrÃ©paration des voyages (mÃªme format que les donnÃ©es d'entraÃ®nement)
voyages_df = pd.DataFrame(nouveaux_voyages)
voyages_features = pd.get_dummies(voyages_df[["ligne", "origine", "destination"]])
voyages_features["heure_depart"] = voyages_df["heure_depart"]
voyages_features["duree"] = voyages_df["duree"]

# Assurer que toutes les colonnes sont prÃ©sentes et dans le bon ordre
for col in features.columns:
    if col not in voyages_features.columns:
        voyages_features[col] = 0
voyages_features = voyages_features[features.columns]

# PrÃ©dictions pour tous les voyages
bus_predits = modele.predict(voyages_features)
probabilites = modele.predict_proba(voyages_features)

# Affichage des rÃ©sultats
print(f"\nðŸ“Œ {len(nouveaux_voyages)} voyages Ã  attribuer :\n")
print(f"   {'#':<3} {'Ligne':<7} {'Trajet':<8} {'Heure':<8} {'DurÃ©e':<8} {'â†’ Bus attribuÃ©':<16} {'Confiance'}")
print(f"   {'â”€'*3} {'â”€'*7} {'â”€'*8} {'â”€'*8} {'â”€'*8} {'â”€'*16} {'â”€'*10}")

for i, (voyage, bus, proba) in enumerate(zip(nouveaux_voyages, bus_predits, probabilites)):
    heure = f"{voyage['heure_depart'] // 60}h{voyage['heure_depart'] % 60:02d}"
    trajet = f"{voyage['origine']}â†’{voyage['destination']}"
    confiance = max(proba)
    print(f"   {i+1:<3} {voyage['ligne']:<7} {trajet:<8} {heure:<8} {voyage['duree']:<8} â†’ {bus:<14} {confiance:.0%}")

# Tableau rÃ©capitulatif par bus
print(f"\nðŸ“Š RÃ©capitulatif par bus :")
recap = pd.Series(bus_predits).value_counts().sort_index()
for bus, count in recap.items():
    voyages_du_bus = [
        v for v, b in zip(nouveaux_voyages, bus_predits) if b == bus
    ]
    lignes_str = ", ".join(
        [f"{v['ligne']} {v['heure_depart']//60}h{v['heure_depart']%60:02d}" for v in voyages_du_bus]
    )
    print(f"   {bus} : {count} voyage(s) â†’ {lignes_str}")


# =============================================
# PARTIE 9 : COURBE D'APPRENTISSAGE ðŸ“‰
# =============================================
print("\n" + "=" * 50)
print("ðŸ“‰ PARTIE 9 : Courbe d'apprentissage (Learning Curve)")
print("=" * 50)
print("\nâ³ Calcul en cours (peut prendre quelques secondes)...")

# Calcul de la courbe d'apprentissage
# On entraÃ®ne le modÃ¨le avec de plus en plus de donnÃ©es
# et on mesure l'erreur Ã  chaque fois
train_sizes, train_scores, test_scores = learning_curve(
    RandomForestClassifier(n_estimators=100, random_state=42),
    features,
    cible,
    train_sizes=np.linspace(0.05, 1.0, 15),  # de 5% Ã  100% des donnÃ©es
    cv=5,                                      # validation croisÃ©e 5 plis
    scoring="accuracy",
    n_jobs=-1,                                 # utiliser tous les cÅ“urs CPU
    random_state=42,
)

# Convertir accuracy en erreur (erreur = 1 - accuracy)
train_errors_mean = (1 - train_scores.mean(axis=1)) * 100  # en %
test_errors_mean = (1 - test_scores.mean(axis=1)) * 100
train_errors_std = train_scores.std(axis=1) * 100
test_errors_std = test_scores.std(axis=1) * 100

# ---- CrÃ©er le graphique ----
fig, ax = plt.subplots(figsize=(10, 7))

# Courbe erreur test (ligne pleine) = validation
ax.plot(
    train_sizes, test_errors_mean,
    "b-", linewidth=2.5, label="Erreur validation (test)", zorder=3
)
# Zone d'incertitude test
ax.fill_between(
    train_sizes,
    test_errors_mean - test_errors_std,
    test_errors_mean + test_errors_std,
    alpha=0.15, color="blue"
)

# Courbe erreur entraÃ®nement (ligne pointillÃ©e)
ax.plot(
    train_sizes, train_errors_mean,
    "b--", linewidth=2.5, label="Erreur entraÃ®nement (train)", zorder=3
)
# Zone d'incertitude train
ax.fill_between(
    train_sizes,
    train_errors_mean - train_errors_std,
    train_errors_mean + train_errors_std,
    alpha=0.1, color="blue"
)

# Ligne de rÃ©fÃ©rence (erreur minimale thÃ©orique)
min_error = min(test_errors_mean)
ax.axhline(
    y=min_error, color="gray", linestyle=":", linewidth=1,
    label=f"Meilleure erreur atteinte ({min_error:.1f}%)"
)

# Mise en forme
ax.set_xlabel("Taille du jeu d'entraÃ®nement (nombre de voyages)", fontsize=12)
ax.set_ylabel("Erreur (%)", fontsize=12)
ax.set_title("Courbe d'apprentissage â€” Random Forest\nAttribution des voyages bus", fontsize=14, fontweight="bold")
ax.legend(fontsize=11, loc="upper right")
ax.grid(True, alpha=0.3)
ax.set_ylim(bottom=0)

# Annotations pÃ©dagogiques
# FlÃ¨che expliquant la zone entre les deux courbes
mid_idx = len(train_sizes) // 3
if test_errors_mean[mid_idx] - train_errors_mean[mid_idx] > 3:
    mid_x = train_sizes[mid_idx]
    mid_y = (test_errors_mean[mid_idx] + train_errors_mean[mid_idx]) / 2
    ax.annotate(
        "",
        xy=(mid_x, mid_y),
        xytext=(mid_x + len(df) * 0.15, mid_y + 5),
        fontsize=9, color="darkblue",
        arrowprops=dict(arrowstyle="->", color="darkblue", lw=1.5),
    )

# Annotation convergence
last_idx = -1
ax.annotate(
    f"Convergence\n~{test_errors_mean[last_idx]:.1f}% erreur",
    xy=(train_sizes[last_idx], test_errors_mean[last_idx]),
    xytext=(train_sizes[last_idx] - len(df) * 0.25, test_errors_mean[last_idx] + 8),
    fontsize=9, color="darkblue",
    arrowprops=dict(arrowstyle="->", color="darkblue", lw=1.5),
)

plt.tight_layout()
plt.savefig("learning_curve_bus.png", dpi=150, bbox_inches="tight")
print("\nâœ… Graphique sauvegardÃ© : learning_curve_bus.png")

# InterprÃ©tation automatique
print("\nðŸ“– Comment lire ce graphique :")
print(f"   â€¢ Avec peu de donnÃ©es, l'erreur de test est Ã©levÃ©e (~{test_errors_mean[0]:.0f}%)")
print(f"   â€¢ Plus on ajoute de donnÃ©es, plus l'erreur baisse")
print(f"   â€¢ L'erreur se stabilise autour de {test_errors_mean[-1]:.1f}%")

ecart_final = test_errors_mean[-1] - train_errors_mean[-1]
if ecart_final > 5:
    print(f"   â€¢ L'Ã©cart train/test reste de {ecart_final:.1f}% â†’ le modÃ¨le overfitte encore")
    print(f"     ðŸ’¡ Solutions : plus de donnÃ©es, rÃ©duire max_depth, ou augmenter min_samples_leaf")
elif ecart_final > 2:
    print(f"   â€¢ L'Ã©cart train/test est de {ecart_final:.1f}% â†’ lÃ©ger overfitting, acceptable")
else:
    print(f"   â€¢ L'Ã©cart train/test est faible ({ecart_final:.1f}%) â†’ bon Ã©quilibre !")

if test_errors_mean[-1] - test_errors_mean[-3] > 1:
    print(f"   â€¢ La courbe descend encore â†’ ajouter des donnÃ©es pourrait amÃ©liorer le modÃ¨le")
else:
    print(f"   â€¢ La courbe est stable â†’ ajouter des donnÃ©es n'amÃ©liorera pas beaucoup le modÃ¨le")


# =============================================
# ðŸŽ“ EXERCICES BONUS
# =============================================
print("\n" + "=" * 50)
print("ðŸŽ“ EXERCICES BONUS POUR ALLER PLUS LOIN")
print("=" * 50)
print("""
1. MODIFIER LES PARAMÃˆTRES DU MODÃˆLE
   - Change n_estimators (50, 200, 500) et observe l'impact
   - Ajoute max_depth=10 pour limiter la profondeur
   - Ajoute min_samples_leaf=5
   â†’ Relance la learning curve pour voir l'effet !

2. AJOUTER DES FEATURES
   - CrÃ©e "est_matin" : features["est_matin"] = (df["heure_depart"] < 720).astype(int)
   - CrÃ©e "heure_arrivee" : features["heure_arrivee"] = df["heure_depart"] + df["duree"]
   - La prÃ©cision s'amÃ©liore-t-elle ?

3. AJOUTER TES PROPRES VOYAGES DE TEST
   - Ajoute des voyages dans la liste 'nouveaux_voyages' (Partie 8)
   - Teste des cas limites : voyage trÃ¨s tÃ´t, trÃ¨s tard, longue durÃ©e...
   - Le modÃ¨le donne-t-il des rÃ©sultats logiques ?

4. TESTER AVEC TES VRAIES DONNÃ‰ES
   - Remplace generer_donnees() par :
     df = pd.read_excel("ton_fichier.xlsx")
   - Adapte les noms de colonnes
   - Lance l'entraÃ®nement et la learning curve !

5. COMPARER AVEC UN AUTRE MODÃˆLE
   - from sklearn.ensemble import GradientBoostingClassifier
   - Trace les deux learning curves sur le mÃªme graphique
   - Quel modÃ¨le converge le plus vite ?

ðŸ’¡ Change UNE SEULE chose Ã  la fois et observe l'impact !
""")